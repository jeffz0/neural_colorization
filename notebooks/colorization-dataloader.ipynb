{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TJWqZnaZTgvH"
   },
   "source": [
    "# Neural Processes Colorization Dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataloader that outputs coordinates and it's positional encoded coordinates along with the gray and color label of the corresponding coordinates' pixels\n",
    "\n",
    "To run:\n",
    "1. Git clone this repo https://github.com/aditya12agd5/divcolor\n",
    "2. Run \"bash get_data.sh\"\n",
    "3. Change 'basedir' and 'listdir' to downloaded filepaths\n",
    "4. Run cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VIGysX3UR5AY"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "\n",
    "import cv2\n",
    "import glob\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RXbKf1Smldqe"
   },
   "source": [
    "### Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class colordata(Dataset):\n",
    "    def __init__(self, basedir, listdir, shape=(32,32), obs_num=100, split='train'):\n",
    "\n",
    "        self.img_fns = []\n",
    "        \n",
    "        self.basedir = basedir\n",
    "        with open('%s/list.%s.vae.txt' % (os.path.join(basedir, listdir), split), 'r') as ftr:\n",
    "            for img_fn in ftr:\n",
    "                self.img_fns.append(img_fn.strip('\\n'))\n",
    "\n",
    "        self.img_num = len(self.img_fns)\n",
    "        self.shape = shape\n",
    "        self.obs_num = obs_num # Number of observations\n",
    "        \n",
    "        # Create mapping from (x,y) coordinates to positional encodings\n",
    "        self.x_enc, self.y_enc = self.create_position_encodings(size=shape[0])\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return self.img_num\n",
    " \n",
    "    def __getitem__(self, idx):\n",
    "        color_ab = np.zeros((2, self.shape[0], self.shape[1]), dtype='f')\n",
    "        recon_const = np.zeros((1, self.shape[0], self.shape[1]), dtype='f')\n",
    "\n",
    "        img_large = cv2.imread(os.path.join(self.basedir,self.img_fns[idx]))\n",
    "        if(self.shape is not None):\n",
    "            img = cv2.resize(img_large, (self.shape[0], self.shape[1]))\n",
    "\n",
    "        img_lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB) # convert to lab color space\n",
    "\n",
    "        img_lab = ((img_lab*2.)/255.)-1. #normalizing\n",
    "\n",
    "        recon_const[0, :, :] = img_lab[..., 0] # gray image\n",
    "\n",
    "        color_ab[0, :, :] = img_lab[..., 1].reshape(1, self.shape[0], self.shape[1])\n",
    "        color_ab[1, :, :] = img_lab[..., 2].reshape(1, self.shape[0], self.shape[1])\n",
    "\n",
    "        # Create list of all possible (x,y) coordinates\n",
    "        indices = list(range(self.shape[0]*self.shape[1]))\n",
    "        np.random.shuffle(indices)\n",
    "        x_coords = np.hstack([np.array(list(range(self.shape[0]))).reshape(1,-1).T]*self.shape[0]).reshape(-1,)\n",
    "        y_coords = np.vstack([np.array(list(range(self.shape[1]))).reshape(1,-1).T]*self.shape[1]).reshape(-1,)\n",
    "\n",
    "        # Select obs_num number of coordinates for encoder\n",
    "        x_coords_obs = x_coords[indices[:self.obs_num]]\n",
    "        y_coords_obs = y_coords[indices[:self.obs_num]]\n",
    "        # Create the positional encoding of the coordinates\n",
    "        x_coords_obs_enc = self.x_enc[x_coords_obs]\n",
    "        y_coords_obs_enc = self.y_enc[y_coords_obs]\n",
    "        color_obs = color_ab[:,x_coords_obs, y_coords_obs]\n",
    "        coords_obs = np.hstack((x_coords_obs_enc,y_coords_obs_enc,color_obs.T))\n",
    "\n",
    "        # Select remaining number of coordinates for prediction decoder\n",
    "        x_coords_pred = x_coords[indices[self.obs_num:]]\n",
    "        y_coords_pred = y_coords[indices[self.obs_num:]]\n",
    "        # Create the positional encoding of the coordinates\n",
    "        x_coords_pred_enc = self.x_enc[x_coords_pred]\n",
    "        y_coords_pred_enc = self.y_enc[y_coords_pred]\n",
    "        coords_pred = np.hstack((x_coords_pred_enc,y_coords_pred_enc))\n",
    "        pred_gt = color_ab[:,x_coords_pred, y_coords_pred].T\n",
    "\n",
    "        return color_ab, recon_const, coords_obs, coords_pred, pred_gt, (x_coords_obs, y_coords_obs), (x_coords_pred, y_coords_pred)\n",
    "\n",
    "    def create_position_encodings(self, size=32):\n",
    "        H, W, C = size, size, 3\n",
    "\n",
    "        L = 10 # parameter for size of encoding\n",
    "\n",
    "        x_linspace = (np.linspace(0, W-1, W)/W)*2 -1 \n",
    "        y_linspace = (np.linspace(0, H-1, H)/H)*2 -1\n",
    "\n",
    "        x_el = []\n",
    "        y_el = []\n",
    "\n",
    "        x_el_hf = []\n",
    "        y_el_hf = []\n",
    "\n",
    "        # cache the values so you don't have to do function calls at every pixel\n",
    "        for el in range(0, L):\n",
    "            val = 2 ** el \n",
    "            x = np.sin(val * np.pi * x_linspace)\n",
    "            x_el.append(x)\n",
    "\n",
    "            x = np.cos(val * np.pi * x_linspace)\n",
    "            x_el_hf.append(x)\n",
    "\n",
    "            y = np.sin(val * np.pi * y_linspace)\n",
    "            y_el.append(y)\n",
    "\n",
    "            y = np.cos(val * np.pi * y_linspace)\n",
    "            y_el_hf.append(y)\n",
    "\n",
    "        x_el = np.array(x_el).T\n",
    "        x_el_hf = np.array(x_el_hf).T\n",
    "        y_el = np.array(y_el).T\n",
    "        y_el_hf = np.array(y_el_hf).T\n",
    "\n",
    "        return np.hstack((x_el, x_el_hf)), np.hstack((y_el, y_el_hf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "basedir = 'pytorch_divcolor'\n",
    "listdir = 'data/imglist/lfw/'\n",
    "\n",
    "data_train = colordata(\\\n",
    "    shape = (32,32), \\\n",
    "    basedir=basedir,\\\n",
    "    listdir=listdir,\\\n",
    "    obs_num = 100,\\\n",
    "    split='train')\n",
    "\n",
    "train_loader = DataLoader(dataset=data_train, num_workers=1,\n",
    "                         batch_size=32, shuffle=True, drop_last=True)\n",
    "\n",
    "data_test = colordata(\\\n",
    "    shape = (32,32), \\\n",
    "    basedir=basedir,\\\n",
    "    listdir=listdir,\\\n",
    "    obs_num = 100,\\\n",
    "    split='test')\n",
    "\n",
    "test_loader = DataLoader(dataset=data_test, num_workers=1,\n",
    "                         batch_size=32, shuffle=True, drop_last=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Color channels (AB) image:\n",
      "     torch.Size([32, 2, 32, 32])\n",
      "Gray channel (L) image:\n",
      "     torch.Size([32, 1, 32, 32])\n",
      "Observation coordinates position encoding (40-dim) concated with color label (2-dim):\n",
      "     torch.Size([32, 100, 42])\n",
      "Prediction coordinates position encoding (40-dim):\n",
      "     torch.Size([32, 924, 40])\n",
      "Prediction's gt color label (2-dim):\n",
      "     torch.Size([32, 924, 2])\n",
      "(x,y) coordinates of observations: \n",
      "     (torch.Size([32, 100]), torch.Size([32, 100]))\n",
      "(x,y) coordinates of predictions: \n",
      "     (torch.Size([32, 924]), torch.Size([32, 924]))\n"
     ]
    }
   ],
   "source": [
    "for i, (color_c, gray_c, obs, pred, pred_gt, (x_coords_obs, y_coords_obs), (x_coords_pred, y_coords_pred)) in enumerate(test_loader):\n",
    "    print(\"Color channels (AB) image:\")\n",
    "    print(\"    \", color_c.shape)\n",
    "    print(\"Gray channel (L) image:\")\n",
    "    print(\"    \", gray_c.shape)\n",
    "    print(\"Observation coordinates position encoding (40-dim) concated with color label (2-dim):\")\n",
    "    print(\"    \", obs.shape)\n",
    "    print(\"Prediction coordinates position encoding (40-dim):\")\n",
    "    print(\"    \", pred.shape)\n",
    "    print(\"Prediction's gt color label (2-dim):\")\n",
    "    print(\"    \", pred_gt.shape)\n",
    "    print(\"(x,y) coordinates of observations: \")\n",
    "    print(\"    \", (x_coords_obs.shape, y_coords_obs.shape))\n",
    "    print(\"(x,y) coordinates of predictions: \")\n",
    "    print(\"    \", (x_coords_pred.shape, y_coords_pred.shape))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "conditional-neural-processes.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
